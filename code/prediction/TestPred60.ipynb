{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.stats\n",
    "\n",
    "from joblib import load\n",
    "from geopy import distance\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trippath =r'C:\\Users\\User\\Desktop\\Data\\Testdata\\tripsample'\n",
    "# trippath = r'C:\\Users\\User\\Desktop\\Data\\test\\trip'\n",
    "Trip_file = glob.glob(trippath + \"/*.txt\")\n",
    "logpath =r'C:\\Users\\User\\Desktop\\Data\\Testdata\\logsample'\n",
    "# logpath = r'C:\\Users\\User\\Desktop\\Data\\test\\log'\n",
    "Log_file = glob.glob(logpath + \"/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_range = [103.6, 104.042]\n",
    "lat_range = [1.238, 1.48]\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    ## Lat Lon ##\n",
    "    df = df[(df['Lat'] >= lat_range[0]) & (df['Lat'] <= lat_range[1])]\n",
    "    df = df[(df['Lon'] >= lon_range[0]) & (df['Lat'] <= lon_range[1])]\n",
    "\n",
    "    \n",
    "    ## Time ##\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format=\"%Y-%m-%d %X\")\n",
    "    df.sort_values(by='Time', inplace=True, ascending=True)\n",
    "\n",
    "    df['Timedif'] = df['Time'] - df['Time'].shift(1)\n",
    "    df['Timedif'] = df['Timedif'].astype(np.int64) // 10 ** 9.\n",
    "    df = df.drop(['Time'], axis=1)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.iloc[0]['Timedif'] = 0\n",
    "    df.iloc[0]['Timedif'] = np.mean(df['Timedif'])\n",
    "\n",
    "    \n",
    "    ## Distance ##\n",
    "    coords = (df['Lat'], df['Lon'])\n",
    "    lat = coords[0]\n",
    "    lon = coords[1]\n",
    "    distdif = []\n",
    "    for i in range(0, len(lat) - 1):\n",
    "        distdif.append(distance.geodesic((lat[i], lon[i]), (lat[i + 1], lon[i + 1])).km)\n",
    "    mean = np.mean(distdif)\n",
    "    distdif.insert(0, mean)\n",
    "    df['Distdif'] = distdif\n",
    "    \n",
    "    \n",
    "    ## Speed ##\n",
    "    speed = []\n",
    "    timedif = df['Timedif']\n",
    "    for i in range(1, len(timedif)):\n",
    "        s = distdif[i] / timedif[i]\n",
    "        if s <= 0.0333:\n",
    "            speed.append(s)\n",
    "        else:\n",
    "            speed.append(0.0333)\n",
    "#         speed.append(distdif[i] / timedif[i]) # km/s\n",
    "    mean = np.mean(speed)\n",
    "    speed.insert(0, mean)\n",
    "    df['Speed'] = speed\n",
    "    \n",
    "    \n",
    "    ## Flag ## - 2 diff source will return 1, same source returns 0\n",
    "    flag = []\n",
    "    source = df['Source']\n",
    "    flag.append(0) # adding 0 to the first value\n",
    "    for i in range(len(source) - 1):\n",
    "        if source[i] != source[i + 1]:\n",
    "            flag.append(1)\n",
    "        else:\n",
    "            flag.append(0)\n",
    "    df['Flag'] = flag    \n",
    "    \n",
    "    \n",
    "    ## Drop first row ##\n",
    "    df = df.drop([0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling inf/-inf/NaN/null values + values at the extremities ##\n",
    "def dropna(df, subset):\n",
    "    ## Check if any index has a null value ##\n",
    "#     print(df.notnull().values.all())\n",
    "#     print(len(df))\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=subset, how=\"any\")\n",
    "#     print(len(df))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Mean\", \"Stdev\", \"Over60\", \"O60U120\", \"Over120\", \"Skewness\", \"Kurtosis\", \"Entropy\", \"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\", \"Q7\", \"Q8\", \"Q9\"]\n",
    "subset = [\"Speed\", \"Distdif\", \"Timedif\", \"Lat\", \"Lon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_process(df, timeLimit): # timeLimit in minutes\n",
    "    out = pd.DataFrame(columns=header)\n",
    "    val = []\n",
    "    \n",
    "    df = dropna(df, subset) #filter away all nan\n",
    "    df = df[df[\"Timedif\"] <= (timeLimit * 60)]\n",
    "    df = df[df[\"Flag\"] == 1] #filter for flag == 1\n",
    "    \n",
    "    total = len(df)\n",
    "    if (total == 0):\n",
    "        return pd.DataFrame()\n",
    "    speed = df[\"Speed\"]\n",
    "    npArr = speed.values\n",
    "    \n",
    "    ## Mean, std ##\n",
    "    mean = np.mean(npArr)\n",
    "    std = np.std(npArr)\n",
    "    val.append(mean)\n",
    "    val.append(std)\n",
    "    \n",
    "    ## % over ##\n",
    "    mask120 = (speed >= 0.0333)\n",
    "    mask60 = (speed >= 0.01666)\n",
    "    count120 = len(df[mask120])\n",
    "    count60 = len(df[mask60])\n",
    "    over60 = count60 / total\n",
    "    over60under120 = (count60 - count120) / total\n",
    "    over120 = count120 / total\n",
    "    val.append(over60)\n",
    "    val.append(over60under120)\n",
    "    val.append(over120)\n",
    "#     print(over120, over60, total)\n",
    "    \n",
    "    ## Skewness ##\n",
    "    val.append(speed.skew(axis=0))\n",
    "    \n",
    "    ## Kurtosis ##\n",
    "    val.append(speed.kurtosis())\n",
    "    \n",
    "    ## Entropy ##\n",
    "    p_data = speed.value_counts()\n",
    "    entropy = scipy.stats.entropy(p_data)\n",
    "    val.append(entropy)\n",
    "    \n",
    "    ## Quantile ##\n",
    "    q1 = speed.quantile(.1)\n",
    "    q2 = speed.quantile(.2)\n",
    "    q3 = speed.quantile(.3)\n",
    "    q4 = speed.quantile(.4)\n",
    "    q5 = speed.quantile(.5)\n",
    "    q6 = speed.quantile(.6)\n",
    "    q7 = speed.quantile(.7)\n",
    "    q8 = speed.quantile(.8)\n",
    "    q9 = speed.quantile(.9)\n",
    "    val.append(q1)\n",
    "    val.append(q2)\n",
    "    val.append(q3)\n",
    "    val.append(q4)\n",
    "    val.append(q5)\n",
    "    val.append(q6)\n",
    "    val.append(q7)\n",
    "    val.append(q8)\n",
    "    val.append(q9)\n",
    "\n",
    "    out.loc[0] = val\n",
    "#     return pd.DataFrame(data=val, dtype=np.float64)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(r'C:\\Users\\User\\Desktop\\Stanley\\Training\\randomforest60.joblib')\n",
    "\n",
    "for tripfile in Trip_file:\n",
    "    string = tripfile.replace(trippath, '')[1: -4]\n",
    "#     index = int(string[3: -1])\n",
    "#     if (index >= indexes_to_skip[0] and index <= indexes_to_skip[1]):\n",
    "#         continue\n",
    "    labels = pd.DataFrame()\n",
    "    records = pd.DataFrame(columns=header)\n",
    "    df1 = pd.read_csv(tripfile, usecols=[1, 2, 3, 4], sep=' ')\n",
    "    for logfile in Log_file:\n",
    "        if string == logfile.replace(logpath,'')[1: -4]:\n",
    "#             print(tripfile.replace(trippath, '')[1:-4])\n",
    "            df2 = pd.read_csv(logfile, usecols=[1,2,3,4], sep=' ')\n",
    "            out = preprocess(pd.concat([df1, df2]))\n",
    "            out = further_process(out, 60) #filter for time <= 60 mins\n",
    "            if (len(out) != 0):\n",
    "                records = pd.concat([records, out], ignore_index=True)\n",
    "                labels = pd.concat([labels, pd.DataFrame(data=[1])], ignore_index=True)\n",
    "        else:\n",
    "            df2 = pd.read_csv(logfile, usecols=[1,2,3,4], sep=' ')\n",
    "            out = preprocess(pd.concat([df1, df2]))\n",
    "            out = further_process(out, 60) #filter for time <= 60 mins\n",
    "            if (len(out) != 0):\n",
    "                records = pd.concat([records, out], ignore_index=True)\n",
    "                labels = pd.concat([labels, pd.DataFrame(data=[0])], ignore_index=True)\n",
    "    ## Removing all null values from kurtosis etc ##\n",
    "    while (not records.notnull().values.all()):\n",
    "        print(\"In while loop\")\n",
    "        print(len(records))\n",
    "        index = records[records[\"Kurtosis\"].isna()].index #change to check for all null, not just Kurtosis\n",
    "        records = records.drop(index)\n",
    "        labels = labels.drop(index)\n",
    "        print(len(records))\n",
    "    ## Predictions ##\n",
    "    pred = model.predict(records)\n",
    "    prob = model.predict_proba(records)\n",
    "    ## Save ##\n",
    "    np.savetxt(string + \"records.txt\", records, delimiter=',')\n",
    "    np.savetxt(string + \"labels.txt\", labels, delimiter=',')\n",
    "    np.savetxt(string + \"predictions.txt\", pred, delimiter=',')\n",
    "    np.savetxt(string + \"probabilities.txt\", prob[:, 1], delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
